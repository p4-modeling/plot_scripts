{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating throughput and packet rate plots from MoonGen data\n",
    "\n",
    "### Input format\n",
    "* MoonGen stdout or csv (tx and rx split to different files)\n",
    "* for stdout: line every second containing the RX or TX data per core\n",
    "```\n",
    "...\n",
    "[Packets counted] RX: 0.10 Mpps, 51 Mbit/s (67 Mbit/s with framing)\n",
    "[Device: id=0] TX: 0.10 Mpps, 51 Mbit/s (67 Mbit/s with framing)\n",
    "[Packets counted] RX: 0.10 Mpps, 51 Mbit/s (67 Mbit/s with framing)\n",
    "[Device: id=0] TX: 0.10 Mpps, 51 Mbit/s (67 Mbit/s with framing)\n",
    "...\n",
    "```\n",
    "* for csv respectively\n",
    "\n",
    "### Features\n",
    "* three types of plotting\n",
    "    * plots data for all individual files\n",
    "        * througput (with and without framing), packet rate\n",
    "    * plots progression over all individual files\n",
    "        * min, max, avg of the above\n",
    "        * requires definition of mapping function\n",
    "        * mapping function maps result of file to x axis value\n",
    "    * plots loop experiment\n",
    "        * define the order of loop variables\n",
    "* figures created in figures/*.tex\n",
    "* externalized data into data/*.tsv\n",
    "* TUMcolors supported\n",
    "* makefile to generate pdfs\n",
    "* same structure as expected by I8 thesis template\n",
    "\n",
    "## You should not have to edit any of the following cells besides the last one\n",
    "* However you might want to tweak some plots manually\n",
    "\n",
    "## errors\n",
    "* if you get tex capacity exceeded when trying to compile the figures you have too many data points\n",
    "    * usually happens for the first plot type as it generates a slope per measurement run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from pprint import pprint\n",
    "rprint=print\n",
    "#from pprint import pprint as print\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: tumcolors only work with python 3.6 and newer\n",
    "from util.tumcolor import tumcolor_cycler\n",
    "from util.i8_tikzplotlib import save_plt, latex_save\n",
    "from util.loop_plot import _plot_loop\n",
    "from util.i8_model import add_model, convert_to_cpu_cycles, add_error_plot, \\\n",
    "                          calculate_2nd_derivative, get_k_maxima, add_derivative_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOONGEN_DATA_OUTPUT = ['mpps', 'mbit', 'mbitcrc']\n",
    "\n",
    "class ParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "def read_moongen_stdout(exp, strip):\n",
    "    data = dict()\n",
    "    valid_file = dict()\n",
    "    with open(exp) as infile:\n",
    "        for line in infile:\n",
    "            # filter unwanted lines\n",
    "            if not (('[Packets counted]' in line or '[Device: id=' in line) and ('RX' in line or 'TX' in line)):\n",
    "                continue\n",
    "                \n",
    "            # check if we reached the last lines containing the summary\n",
    "            summary = False\n",
    "            if 'StdDev' in line and 'total' in line:\n",
    "                summary = True\n",
    "                \n",
    "            cid = 0\n",
    "            direction = 'rx'\n",
    "            mpps = 0 \n",
    "            mbit = 0\n",
    "            mbitcrc = 0\n",
    "            \n",
    "            parts = line.split('] ')            \n",
    "            # get ID\n",
    "            if parts[0].endswith('Packets counted'):\n",
    "                #TODO does this make sense?\n",
    "                cid = 0\n",
    "            else:\n",
    "                cid = int(parts[0].split('=')[-1])\n",
    "                \n",
    "            # get direction\n",
    "            parts = parts[1].split(' ')\n",
    "            if parts[0].startswith('RX'):\n",
    "                direction = 'rx'\n",
    "            elif parts[0].startswith('TX'):\n",
    "                direction = 'tx'\n",
    "            else:\n",
    "                raise ValueError('Unable to parse direction: {}'.format(line))\n",
    "            \n",
    "            # prepare structure\n",
    "            if not cid in data:\n",
    "                data[cid] = dict()\n",
    "            if not direction in data[cid]:\n",
    "                data[cid][direction] = dict()\n",
    "            for item in MOONGEN_DATA_OUTPUT:\n",
    "                if not item in data[cid][direction]:\n",
    "                    data[cid][direction][item] = list()\n",
    "                \n",
    "            # get other data\n",
    "            if not summary:\n",
    "                mpps = float(parts[1])\n",
    "                mbit = float(parts[3])\n",
    "                mbitcrc = float(parts[5][1:])\n",
    "                \n",
    "                data[cid][direction]['mpps'].append(mpps)\n",
    "                data[cid][direction]['mbit'].append(mbit)\n",
    "                data[cid][direction]['mbitcrc'].append(mbitcrc)\n",
    "                valid_file[direction] = True\n",
    "            else:\n",
    "                mpps = float(parts[1])\n",
    "                mbit = float(parts[5])\n",
    "                mbitcrc = float(parts[9][1:])\n",
    "                \n",
    "                data[cid][direction]['avg_mg_mpps'] = mpps\n",
    "                data[cid][direction]['avg_mg_mbit'] = mbit\n",
    "                data[cid][direction]['avg_mg_mbitcrc'] = mbitcrc\n",
    "                \n",
    "                # strip from head and tail of data\n",
    "                if strip:\n",
    "                    data[cid][direction]['mpps'] = data[cid][direction]['mpps'][strip:-(strip+1)]\n",
    "                    data[cid][direction]['mbit'] = data[cid][direction]['mbit'][strip:-(strip+1)]\n",
    "                    data[cid][direction]['mbitcrc'] = data[cid][direction]['mbitcrc'][strip:-(strip+1)]\n",
    "                \n",
    "                # add self calculated averages with skips as default\n",
    "                data[cid][direction]['avg_mpps'] = np.mean(data[cid][direction]['mpps'])\n",
    "                data[cid][direction]['avg_mbit'] = np.mean(data[cid][direction]['mbit'])\n",
    "                data[cid][direction]['avg_mbitcrc'] = np.mean(data[cid][direction]['mbitcrc'])\n",
    "                \n",
    "                valid_file[direction + '_summary'] = True\n",
    "        if not len(valid_file.keys()) == 4:\n",
    "            raise ParsingError('Invalid file: {}'.format(valid_file))\n",
    "                \n",
    "    return data\n",
    "\n",
    "def read_moongen_csv(exp, throughput_file, strip, repeat=1, only_core_id=1, only_direction='rx'):\n",
    "    \n",
    "    # split location, replace tx with rx and vice versa\n",
    "    parts = [p for p in throughput_file.split('*') if 'rx' in p or 'tx' in p]\n",
    "    if not len(parts) == 1:\n",
    "        print('unknown throughput_file format, must include exactly one of tx or rx in name')\n",
    "    throughput_file = parts[0]\n",
    "        \n",
    "    \n",
    "    if 'tx' in throughput_file:\n",
    "        throughput_file_2 = throughput_file.replace('tx', 'rx')\n",
    "    elif 'rx' in throughput_file:\n",
    "        throughput_file_2 = throughput_file.replace('rx', 'tx')\n",
    "    exps = [exp, exp.replace(throughput_file, throughput_file_2)]\n",
    "    \n",
    "    max_value = 0\n",
    "    max_idx = 0\n",
    "    datas = []\n",
    "    for rep in range(1, repeat + 1):\n",
    "        data = {}\n",
    "        for exp in exps:\n",
    "            exp = exp[:-1] + str(rep)\n",
    "            with open(exp) as infile:\n",
    "                content = csv.DictReader(infile, delimiter=',')\n",
    "                for line in content:\n",
    "                    # no core id, use device id\n",
    "                    cid = int(line['Device'].split('=')[1])\n",
    "                    direction = line['Direction'].lower()\n",
    "                    mpps = float(line['PacketRate'])\n",
    "                    mbit = float(line['Mbit'])\n",
    "                    mbitcrc = float(line['MbitWithFraming'])\n",
    "                    \n",
    "                    if not cid in data:\n",
    "                        data[cid] = dict()\n",
    "                    if not direction in data[cid]:\n",
    "                        data[cid][direction] = dict()\n",
    "                    for item in MOONGEN_DATA_OUTPUT:\n",
    "                        if not item in data[cid][direction]:\n",
    "                            data[cid][direction][item] = list()\n",
    "                            \n",
    "                    data[cid][direction]['mpps'].append(mpps)\n",
    "                    data[cid][direction]['mbit'].append(mbit)\n",
    "                    data[cid][direction]['mbitcrc'].append(mbitcrc)\n",
    "        \n",
    "        # add average values\n",
    "        for cid, dat in data.items():\n",
    "            for direction, dat in dat.items():\n",
    "                for t in MOONGEN_DATA_OUTPUT:\n",
    "                    data[cid][direction]['avg_' + t] = sum(dat[t]) / len(dat[t])\n",
    "                    # also update max value for later\n",
    "                    if cid == only_core_id and direction == only_direction and t == 'mpps':\n",
    "                        if data[cid][direction]['avg_' + t] > max_value:\n",
    "                            max_value = data[cid][direction]['avg_' + t]\n",
    "                            max_idx = rep\n",
    "    \n",
    "                # strip from head and tail of data\n",
    "                if strip:\n",
    "                    data[cid][direction]['mpps'] = data[cid][direction]['mpps'][strip:-(strip+1)]\n",
    "                    data[cid][direction]['mbit'] = data[cid][direction]['mbit'][strip:-(strip+1)]\n",
    "                    data[cid][direction]['mbitcrc'] = data[cid][direction]['mbitcrc'][strip:-(strip+1)]\n",
    "        datas.append(data)\n",
    "                \n",
    "    # only return repetition of maximum value\n",
    "    return datas[max_idx - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_values(data, prefix, func):\n",
    "    for cid, data2 in data.items():\n",
    "        for direction, data3 in data2.items():\n",
    "            for item in MOONGEN_DATA_OUTPUT:\n",
    "                data[cid][direction][prefix + '_' + item] = func(data3[item])\n",
    "                \n",
    "def add_progression_x_value(progression_mapping_function, exp, data):\n",
    "    for cid, data2 in data.items():\n",
    "        for direction, data3 in data2.items():\n",
    "            data[cid][direction]['x_value'] = progression_mapping_function(exp, data)\n",
    "                \n",
    "def add_packet_loss(data, only_core_id=1, only_direction='rx'):\n",
    "    global found_loss\n",
    "    global counter\n",
    "    sent = 0\n",
    "    recv = 0\n",
    "    for cid, data2 in data.items():\n",
    "        for direction, data3 in data2.items():\n",
    "            if direction == 'tx':\n",
    "                sent = data3['max_mpps']\n",
    "            else:\n",
    "                recv = data3['max_mpps']\n",
    "    loss = sent - recv\n",
    "    data[only_core_id][only_direction]['loss'] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tp_data(paths, basepath='/', throughput_file='histogram.csv', throughput_location='stdout',\n",
    "                    throughput_strip=0, progression_mapping_function=None,\n",
    "                    repeat=1, only_direction='rx', only_core_id=1, **args):\n",
    "    data = {}\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "\n",
    "    for path in paths:\n",
    "        name = None\n",
    "        if not isinstance(path, tuple):\n",
    "            name = path.replace('_', '-') # tex friendly path\n",
    "        else:\n",
    "            name = path[1]\n",
    "            path = path[0]\n",
    "            \n",
    "        extended_path = os.path.join(basepath, path)\n",
    "        rprint('Processing ' + extended_path)\n",
    "        experiment = os.path.join(extended_path, throughput_file + '_1')\n",
    "        \n",
    "        subexperiments = glob(experiment)\n",
    "        update_name = False\n",
    "        base_name = name\n",
    "        if len(subexperiments) > 1:\n",
    "            update_name = True\n",
    "        \n",
    "        for exp in sorted(subexperiments):\n",
    "            # replace everything that is not wildcard\n",
    "            if not (basepath == '.' or basepath == '..'):\n",
    "                histo = exp.replace(basepath, '')\n",
    "            histo = histo.replace(path, '')\n",
    "            histo = histo.replace(throughput_file, '')\n",
    "            histo = histo.replace('//', '/')\n",
    "            histo = histo[:-1]\n",
    "            \n",
    "            #rprint('Subexperiment ' + histo)\n",
    "            if update_name:\n",
    "                name = base_name + histo\n",
    "                \n",
    "            # load data\n",
    "            try:\n",
    "                if throughput_location == 'stdout':\n",
    "                    raw_data = read_moongen_stdout(exp, throughput_strip)\n",
    "                elif throughput_location == 'split':\n",
    "                    raw_data = read_moongen_csv(exp, throughput_file, throughput_strip,\n",
    "                                                repeat=repeat, only_direction=only_direction,\n",
    "                                                only_core_id=only_core_id)\n",
    "                else:\n",
    "                    print('unknown throughput_location')\n",
    "                    return\n",
    "            except (FileNotFoundError, ParsingError) as exce:\n",
    "                rprint('Skipping {} - {}'.format(histo, exce), file=sys.stderr)\n",
    "                continue\n",
    "                \n",
    "            # different processing steps\n",
    "            add_values(raw_data, 'max', max)\n",
    "            add_values(raw_data, 'min', min)\n",
    "            add_packet_loss(raw_data, only_direction=only_direction, only_core_id=only_core_id)\n",
    "            if progression_mapping_function:\n",
    "                add_progression_x_value(progression_mapping_function, exp, raw_data)\n",
    "            \n",
    "            # store data\n",
    "            data[name] = {}\n",
    "            data[name]['tp'] = raw_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rate(data, name='', key='mbit', ylabel='Throughput [Mbit/s]', additional_plot_exports=None,\n",
    "              only_direction=None, only_core_id=None):\n",
    "    if not additional_plot_exports:\n",
    "        additional_plot_exports = []\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    max_x_value = 0\n",
    "    for exp, data in sorted(data.items()):\n",
    "        data = data['tp']\n",
    "        for cid, data in data.items():\n",
    "            if only_core_id and not cid == only_core_id:\n",
    "                continue\n",
    "            for direction, data in data.items():\n",
    "                if only_direction and not direction == only_direction:\n",
    "                    continue\n",
    "                data = data[key]\n",
    "                \n",
    "                xs = range(len(data))\n",
    "                ys = data\n",
    "                \n",
    "                max_x_value = len(data) - 1\n",
    "                \n",
    "                label = exp\n",
    "                if not only_core_id:\n",
    "                    label += ' - c' + str(cid)\n",
    "                if not only_direction:\n",
    "                    label += ' - ' + direction\n",
    "                ax.plot(xs, ys, label=label)\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=0)\n",
    "    plt.xlim(right=max_x_value)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel=ylabel,\n",
    "           xlabel='Experiment Duration [s]')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    save_plt(key, name=name)\n",
    "    for ape in additional_plot_exports:\n",
    "        rprint('Additional export as {}'.format(ape))\n",
    "        savefig('figures/{}_{}.{}'.format(name, key, ape), format=ape)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loop(name, content, mapping, tp_data, key='max_mbit',\n",
    "              additional_plot_exports=None, only_direction=None, only_core_id=None,\n",
    "              loop_log_scale=False, convert_to_cycles=False, **kwargs):\n",
    "    if not additional_plot_exports:\n",
    "        additional_plot_exports = []\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    axis_label = None\n",
    "    xss = {}\n",
    "    yss = {}\n",
    "    loss = {}\n",
    "    mapped = {}\n",
    "    \n",
    "    # gather data based on mapping\n",
    "    for exp, run, type, label in content:\n",
    "        axis_label = list(type.keys())[0]\n",
    "        if label not in xss:\n",
    "            xss[label] = []\n",
    "            yss[label] = {}\n",
    "            loss[label] = {}\n",
    "        xss[label].append(list(type.values())[0])\n",
    "        try:\n",
    "            mapped[label] = tp_data[mapping[exp][run]]\n",
    "        except KeyError as exce:\n",
    "            continue\n",
    "        else:\n",
    "            mapped[label] = mapped[label]['tp']\n",
    "            for cid, data in mapped[label].items():\n",
    "                for direction, data in data.items():\n",
    "                    y = data[key]\n",
    "                    full = '{}-{}-{}'.format(label, cid, direction)\n",
    "                    try:\n",
    "                        yss[label][full].append(y)\n",
    "                    except KeyError:\n",
    "                        yss[label][full] = [y]\n",
    "                    try:\n",
    "                        lo = data['loss']\n",
    "                        try:\n",
    "                            loss[label][full].append(lo)\n",
    "                        except KeyError:\n",
    "                            loss[label][full] = [lo]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "        \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    loss_data = []\n",
    "    labels = []\n",
    "    max_x_value = 0\n",
    "    min_x_value = 1000000\n",
    "    for exp, data in sorted(mapped.items()):\n",
    "        for cid, data in sorted(data.items()):\n",
    "            if only_core_id and not cid == only_core_id:\n",
    "                continue\n",
    "            for direction, data in sorted(data.items()):\n",
    "                if only_direction and not direction == only_direction:\n",
    "                    continue\n",
    "                full = '{}-{}-{}'.format(exp, cid, direction)\n",
    "                label = exp\n",
    "                if not only_core_id:\n",
    "                    label += '-' + str(cid)\n",
    "                if not only_direction:\n",
    "                    label += '-' + direction\n",
    "                ys = yss[exp][full]\n",
    "                xs = xss[exp]\n",
    "                lo = loss[exp][full]\n",
    "                zipped = list(zip(xs, ys, lo))\n",
    "                zipped.sort(key=lambda tup: tup[0])\n",
    "                xs, ys, lo = zip(*zipped)\n",
    "                x_data.append(xs)\n",
    "                y_data.append(ys)\n",
    "                loss_data.append(lo)\n",
    "                labels.append(label)\n",
    "                \n",
    "                max_x_value = max(max_x_value, max(xs))\n",
    "                min_x_value = min(max_x_value, min(xs))\n",
    "                \n",
    "                ax.plot(xs, ys, marker='x', label=latex_save(label))\n",
    "    \n",
    "    # process x axis label\n",
    "    axis_label = ' '.join([part.capitalize() for part in axis_label.split('_')])\n",
    "    \n",
    "    # axis limits\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=min_x_value)\n",
    "    plt.xlim(right=max_x_value)\n",
    "    if loop_log_scale:\n",
    "        plt.xscale('log')\n",
    "        axis_label += ' [log]'\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel=METRIC_TO_LABEL[key],\n",
    "           xlabel=axis_label)\n",
    "    \n",
    "    if kwargs.get('model_parameters'):\n",
    "        modelp = kwargs.get('model_parameters')\n",
    "        # add model now that we made all configs in case of abort\n",
    "        error_plot = []\n",
    "        derivatives = []\n",
    "        maximas = []\n",
    "        for i in range(0, modelp.get('num_graphs', 1)):\n",
    "            if not len(x_data) >= i + 1:\n",
    "                break\n",
    "            end = 0\n",
    "            if modelp.get('end'):\n",
    "                num = len(x_data[i])\n",
    "                end = num - modelp.get('end')\n",
    "        \n",
    "            # calculate derivative\n",
    "            derivative = calculate_2nd_derivative(x_data[i], y_data[i], log=loop_log_scale)\n",
    "            maxima = get_k_maxima(derivative[2], k=modelp.get('maxima_k', 10),\n",
    "                                  j=modelp.get('maxima_j', 0), max_index=end)\n",
    "            maximas.append(maxima)\n",
    "            derivative.append(maxima)\n",
    "            derivatives.append((x_data[i], derivative, i))\n",
    "            \n",
    "            error_plot += add_model(x_data, y_data, ax, modelp,\n",
    "                                    maximum=14.88, graph=i, end=end, maxima=maxima)\n",
    "        \n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    save_plt('loop_{}'.format(key), name=name)\n",
    "    for ape in additional_plot_exports:\n",
    "        rprint('Additional export as {}'.format(ape))\n",
    "        savefig('figures/{}_loop_{}.{}'.format(name, key, ape), format=ape)\n",
    "    plt.show()\n",
    "    \n",
    "    if kwargs.get('model_parameters', False):\n",
    "        add_error_plot(plt, error_plot, name, key=key, log_scale=loop_log_scale, axis_label=axis_label,\n",
    "                       additional_plot_exports=additional_plot_exports)\n",
    "        \n",
    "        add_derivative_plot(plt, derivatives, name, key=key, log_scale=loop_log_scale, axis_label=axis_label,\n",
    "                            additional_plot_exports=additional_plot_exports)\n",
    "    \n",
    "    # also model the cpu cycles per packet\n",
    "    if not convert_to_cycles:\n",
    "        return\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    cycle_xs = []\n",
    "    cycle_ys = []\n",
    "    max_x_value = 0\n",
    "    min_x_value = 1000000\n",
    "    for xs, ys, loss, label in zip(x_data, y_data, loss_data, labels):\n",
    "        cores = int(label.split('cpu_cores-')[-1])\n",
    "        current_freq = None\n",
    "        if convert_to_cycles == 'from_loop':\n",
    "            current_freq = list(xs)\n",
    "        else:\n",
    "            current_freq = float(convert_to_cycles)\n",
    "        ys = convert_to_cpu_cycles(ys, current_freq, loss,\n",
    "                                   loss_level=0.1, filter_surrounding=4, cores=cores)\n",
    "                \n",
    "        # remove -1s\n",
    "        reduced = [(x, y) for x, y in zip(xs, ys) if y > -1]\n",
    "        if not reduced:\n",
    "            continue\n",
    "        xs, ys = list(zip(*reduced))\n",
    "        \n",
    "        cycle_xs.append(xs)\n",
    "        cycle_ys.append(ys)\n",
    "        \n",
    "        max_x_value = max(max_x_value, max(xs))\n",
    "        min_x_value = min(min_x_value, min(xs))\n",
    "                \n",
    "        ax.plot(xs, ys, marker='x', label=latex_save(label))\n",
    "    \n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=min_x_value)\n",
    "    plt.xlim(right=max_x_value)\n",
    "    if loop_log_scale:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    ax.grid()\n",
    "    ax.set(ylabel=\"Cycles per Packet [-]\",\n",
    "           xlabel=axis_label)\n",
    "        \n",
    "    if kwargs.get('model_parameters'):\n",
    "        modelp = kwargs.get('model_parameters')\n",
    "        # add model now that we made all configs in case of abort\n",
    "        error_plot = []\n",
    "        derivatives = []\n",
    "        for i in range(0, modelp.get('num_graphs', 1)):\n",
    "            if len(cycle_ys) <= i:\n",
    "                continue\n",
    "            if not len(cycle_xs) >= i + 1:\n",
    "                break\n",
    "            end = 0\n",
    "            if modelp.get('end'):\n",
    "                num = len(cycle_xs[i])\n",
    "                end = num - modelp.get('end')\n",
    "        \n",
    "            # calculate derivative\n",
    "            derivative = calculate_2nd_derivative(cycle_xs[i], cycle_ys[i], log=loop_log_scale)\n",
    "            derivative.append(maxima)\n",
    "            derivatives.append((cycle_xs[i], derivative, i))\n",
    "            maxima = get_k_maxima(derivative[2], k=modelp.get('maxima_k', 10),\n",
    "                                  j=modelp.get('maxima_j', 0), max_index=end)\n",
    "            maximas[i] += maxima\n",
    "            maxima = sorted(list(set(maximas[i])))\n",
    "            \n",
    "            # do not apply model start and end again this time\n",
    "            error_plot += add_model(cycle_xs, cycle_ys, ax, modelp,\n",
    "                                    maximum=2* max(cycle_ys[i]), graph=i, end=end, maxima=maxima)\n",
    "        \n",
    "    \n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    save_plt('loop_cycles_{}'.format(key), name=name)\n",
    "    for ape in additional_plot_exports:\n",
    "        rprint('Additional export as {}'.format(ape))\n",
    "        savefig('figures/{}_loop_cycles_{}.{}'.format(name, key, ape), format=ape)\n",
    "    plt.show()\n",
    "    \n",
    "    if kwargs.get('model_parameters'):\n",
    "        add_error_plot(plt, error_plot, name, name_extra='cycles', key=key, log_scale=loop_log_scale, axis_label=axis_label,\n",
    "                       additional_plot_exports=additional_plot_exports)\n",
    "        \n",
    "        add_derivative_plot(plt, derivatives, name, name_extra='cycles', key=key,\n",
    "                            log_scale=loop_log_scale, axis_label=axis_label,\n",
    "                            additional_plot_exports=additional_plot_exports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_individual_runs(tp_data, name, ape, only_direction, only_core_id):\n",
    "    print('---------- regular plots of individual measurements -----------------------')\n",
    "    print('this will include every single measurement run and might take long to generate the graph')\n",
    "    print('set default_plots=False if it takes too long')\n",
    "    # different plot types for moongen throughput data\n",
    "    plot_rate(tp_data, name, only_direction=only_direction, only_core_id=only_core_id, key='mbit', ylabel='Throughput [Mbit/s]', additional_plot_exports=ape)\n",
    "    plot_rate(tp_data, name, only_direction=only_direction, only_core_id=only_core_id, key='mbitcrc', ylabel='Throughput (with Framing) [Mbit/s]', additional_plot_exports=ape)\n",
    "    plot_rate(tp_data, name, only_direction=only_direction, only_core_id=only_core_id, key='mpps', ylabel='Packet Rate [Mpps]', additional_plot_exports=ape)\n",
    "    \n",
    "def _plot_progression(tp_data, name, progression_x_label, metrics, ape, only_direction):\n",
    "    print('------------ progression plots ----------------')\n",
    "    for metric in metrics:\n",
    "        plot_progression(tp_data, name, key=metric, ylabel=METRIC_TO_LABEL[metric], xlabel=progression_x_label,\n",
    "                         additional_plot_exports=ape, only_direction=only_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(paths, **kwargs):\n",
    "    \n",
    "    # extract throughput data\n",
    "    tp_data = extract_tp_data(paths, **kwargs)\n",
    "    \n",
    "    if not tp_data:\n",
    "        rprint('No throughput data found', file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    if kwargs.get('default_plots'):\n",
    "        _plot_individual_runs(tp_data, **kwargs)\n",
    "    \n",
    "    if not kwargs.get('metrics'):\n",
    "        print('you need to define the metrics of interest (METRIC_TO_LABEL.keys())')\n",
    "        return\n",
    "        \n",
    "    if kwargs.get('loop_file'):\n",
    "        _plot_loop(paths, tp_data, plot_loop, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_TO_LABEL = {\n",
    "    'max_mbit'   : 'Throughput [Mbit/s]',\n",
    "    'max_mbitcrc': 'Throughput (with Framing) [Mbit/s]',\n",
    "    'max_mpps'   : 'Packet Rate [Mpps]',\n",
    "    'avg_mbit'   : 'Average Throughput [Mbit/s]',\n",
    "    'avg_mbitcrc': 'Average Throughput (with Framing) [Mbit/s]',\n",
    "    'avg_mpps'   : 'Average Packet Rate [Mpps]',\n",
    "    'min_mbit'   : 'Minimum Throughput [Mbit/s]',\n",
    "    'min_mbitcrc': 'Minimum Throughput (with Framing) [Mbit/s]',\n",
    "    'min_mpps'   : 'Minimum Packet Rate [Mpps]',\n",
    "    'avg_mg_mbit'   : 'Average Throughput [Mbit/s]',\n",
    "    'avg_mg_mbitcrc': 'Average Throughput (with Framing) [Mbit/s]',\n",
    "    'avg_mg_mpps'   : 'Average Packet Rate [Mpps]',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your edits in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argument_parser():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='run throughput script')\n",
    "    parser.add_argument('-l', '--local-data', action='store_true',\n",
    "                        help='Run with local data')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument parser\n",
    "args = None\n",
    "if not sys.argv[0].endswith('ipykernel_launcher.py'):\n",
    "    args = argument_parser()\n",
    " \n",
    "local_data = args and args.local_data or False\n",
    "\n",
    "# configuration\n",
    "configuration = None\n",
    "# templated from generator script\n",
    "#$configuration\n",
    "if not configuration:\n",
    "    # default for testing\n",
    "    configuration = {'convert_to_cycles': 2.0,\n",
    " 'dut': 'cesis',\n",
    " 'experiment_name': 'number_entries',\n",
    " 'latency_rates': [0.1, 0.5, 0.7],\n",
    " 'loadgen': 'nida',\n",
    " 'log_scale': 'True',\n",
    " 'loop_plot_per': ['packet_size'],\n",
    " 'loop_x_axis': 'table_entries',\n",
    " 'model_end': 0,\n",
    " 'model_parts': [3],\n",
    " 'model_start': 0,\n",
    " 'only_core_id': 1,\n",
    " 'perf_stat_events': [['r08d1', 'L1_cache_misses'],\n",
    "                      ['r10d1', 'L2_cache_misses'],\n",
    "                      ['r20d1', 'L3_cache_misses']],\n",
    " 'repetitions': 3,\n",
    " 'result_dir_file': '/home/scholzd/component_benchmarking/experiments/p4_tapas/mat/table_entries/result_directory.txt',\n",
    " 'target': 'p4_t4p4s'}\n",
    "    \n",
    "print('Using local data: ' + str(local_data))\n",
    "# in this case, modify result_dir_file and result_dirs with local path in data repository\n",
    "if local_data:\n",
    "    configuration['result_dir_file'] = '../result_directory.txt'\n",
    "    \n",
    "result_dir = None\n",
    "with open(configuration['result_dir_file'], 'r') as fh:\n",
    "    # one per row, filter duplicates and empty last line\n",
    "    result_dirs = sorted(list(set(fh.read().split('\\n')[:-1])))\n",
    "    \n",
    "\n",
    "if local_data:\n",
    "    result_dirs = [os.path.join('../data/', result_dir.split('/')[-1]) for result_dir in result_dirs]\n",
    "    \n",
    "if not local_data:\n",
    "    import socket\n",
    "    hostname = socket.gethostname()\n",
    "    print('Results on node ' + hostname)\n",
    "    \n",
    "print('Found result directories')\n",
    "pprint(result_dirs)\n",
    "\n",
    "print('Using configuration:')\n",
    "pprint(configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = result_dirs[-1]\n",
    "print('Result data in:')\n",
    "print(result_dir)\n",
    "\n",
    "RESULTS=os.path.join(result_dir, configuration['loadgen'])\n",
    "THROUGHPUT_FILENAME = 'throughput-max-tx_run*.csv'\n",
    "METRICS = ['max_mpps']\n",
    "LOOP_FILENAME = '*_measurement_run*.loop'\n",
    "\n",
    "model_parameters = {\n",
    "    'parts': configuration['model_parts'],\n",
    "    'bruteforce': [2], \n",
    "    'end': configuration['model_end'],\n",
    "    'start': configuration['model_start'],\n",
    "    \n",
    "    'num_graphs': 1,\n",
    "    'show_best_x': 1,\n",
    "    \n",
    "    'maxima_k': 10,\n",
    "    'maxima_j': 0,\n",
    "    \n",
    "    'gamma': 1e-05,\n",
    "    'comp_method': 'sMAPE',\n",
    "    'epsilon': 0.005,\n",
    "    'epsilon_rel': 0.005,\n",
    "}\n",
    "\n",
    "plot(\n",
    "    [\n",
    "        ('', configuration['experiment_name']),\n",
    "    ],\n",
    "    basepath=RESULTS,\n",
    "    name=configuration['target'],\n",
    "    throughput_file=THROUGHPUT_FILENAME,\n",
    "    throughput_location='split',\n",
    "    throughput_strip=1,\n",
    "    \n",
    "    metrics=METRICS,\n",
    "    default_plots=False,\n",
    "    only_direction='rx',\n",
    "    only_core_id=configuration['only_core_id'],\n",
    "    repeat=configuration['repetitions'],\n",
    "    \n",
    "    convert_to_cycles=configuration['convert_to_cycles'],\n",
    "    \n",
    "    loop_file=LOOP_FILENAME,\n",
    "    loop_x_axis=configuration['loop_x_axis'],\n",
    "    loop_plot_per=configuration['loop_plot_per'],\n",
    "    loop_log_scale=configuration['log_scale'],\n",
    "    \n",
    "    model_parameters=model_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
