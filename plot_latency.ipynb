{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating histogram, CDF and HDR plots from histrogram data in .csv format\n",
    "* also generates sequence plot from sequence data in .csv format\n",
    "\n",
    "### Input format\n",
    "* histogram data in csv format with two columns\n",
    "* latency (in nanosecond)\n",
    "* occurence\n",
    "* e.g. as generated by MoonGen\n",
    "* example:\n",
    "```\n",
    "1663,1\n",
    "1668,22\n",
    "1669,76\n",
    "1674,13\n",
    "1675,930\n",
    "1680,73\n",
    "1681,449\n",
    "```\n",
    "\n",
    "### Features\n",
    "* histogram, normalized histogram, CDF and HDR generation\n",
    "* optinal sequence plot generation\n",
    "* figures created in figures/*.tex\n",
    "* externalized data into data/*.tsv\n",
    "* TUMcolors supported\n",
    "* makefile to generate pdfs\n",
    "* same structure as expected by I8 thesis template\n",
    "* latency is converted to microsecond\n",
    "* histogram data is binned to microsecond resolution\n",
    "\n",
    "## You should not have to edit any of the following cells besides the last one\n",
    "* However you might want to tweak some plots manually\n",
    "\n",
    "## errors\n",
    "* if you get tex capacity exceeded when trying to compile the figures you have too many data points\n",
    " * solution: less bins, by rounding more (e.g. 10 or 100 microsecond resolution)\n",
    " * change: in to_microsecond change the dividend (from 1000 to 10000 or 100000)\n",
    " * result: not microsecond resolution/bins but 10 or 100 microsecond\n",
    " * dont forget to either update all axis labels or convert back to microsecond after binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "rprint=print\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: tumcolors only work with python 3.6 and newer\n",
    "from util.tumcolor import tumcolor_cycler\n",
    "from util.i8_tikzplotlib import get_tikz_code, save_plt\n",
    "from util.loop_plot import _plot_loop\n",
    "from util.i8_model import add_model, add_error_plot, \\\n",
    "                          calculate_2nd_derivative, get_k_maxima, add_derivative_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for command line invocation\n",
    "def run_from_cli():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Generating plots from histogram data')\n",
    "    parser.add_argument('basepath', metavar='BASEPATH', type=str,\n",
    "                        help='Base path for all experiments')\n",
    "    parser.add_argument('--histogram-filename', metavar='HIST_FILENAME', type=str, default='histogram.csv',\n",
    "                        help='name of the histogram data file, wildcard possible')\n",
    "    parser.add_argument('--sequence-filename', metavar='SEQ_FILENAME', type=str, default='',\n",
    "                        help='name of the sequence data file, wildcard possible')\n",
    "    parser.add_argument('--name', type=str, default='',\n",
    "                        help='suffix for generated files, e.g. hdr-NAME.tex')\n",
    "    parser.add_argument('path', metavar='PATH', type=str, nargs='+',\n",
    "                        help='path to one or more csv file(s), will be RESULTS/<path>/HIST_FILENAME')\n",
    "    parser.add_argument('--label', metavar='LABEL', type=str, action='append',\n",
    "                        help='Nicer name for experiments')\n",
    "    parser.add_argument('--round-ms-digits', metavar='ROUND', type=int, default=3,\n",
    "                        help='Round to ROUND ms digits for binning')\n",
    "    parser.add_argument('--histogram-bar-width', metavar='BAR_WIDTH', type=float, default=0.005,\n",
    "                        help='Width for histogram bars')\n",
    "    parser.add_argument('--loop-log-scale', action='store_true',\n",
    "                        help='Log scale for loop plot x axis')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    if args.label and not len(args.label) == len(args.path):\n",
    "        raise argparse.ArgumentTypeError('Must provide a label for either no or all paths')\n",
    "        \n",
    "    experiments = []\n",
    "    if args.label:\n",
    "        experiments = list(zip(args.path, args.label))\n",
    "    else:\n",
    "        experiments = args.path\n",
    "        \n",
    "    plot(experiments,\n",
    "         basepath=args.basepath,\n",
    "         histogram_file=args.histogram_filename,\n",
    "         sequence_file=args.sequence_filename,\n",
    "         name=args.name,\n",
    "         round_ms_digits=args.round_ms_digits,\n",
    "         histogram_bar_width=args.histogram_bar_width,\n",
    "         \n",
    "         loop_log_scale=args.loop_log_scale,\n",
    "    )\n",
    "        \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_2c_csv(exp):\n",
    "    data = dict()\n",
    "    with open(exp) as infile:\n",
    "        for line in infile:\n",
    "            lat, occ = line.strip().split(',')\n",
    "            data[int(lat)] = int(occ)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_microsecond(data, keys=True, values=False):\n",
    "    if keys and values:\n",
    "        return {k / 1000: v / 1000 for k, v in data.items()}\n",
    "    if keys:\n",
    "        return {k / 1000: v for k, v in data.items()}\n",
    "    if values:\n",
    "        return {k: v / 1000 for k, v in data.items()}\n",
    "    \n",
    "def to_ms_bins(data, round_ms_digits=3):\n",
    "    binned = {}\n",
    "    for k, v in data.items():\n",
    "        rounded = round(k, round_ms_digits)\n",
    "        if rounded not in binned:\n",
    "            binned[rounded] = v\n",
    "        else:\n",
    "            binned[rounded] += v\n",
    "    return binned\n",
    "\n",
    "def to_expanded(data):\n",
    "    expanded = []\n",
    "    for val, occ in data.items():\n",
    "        expanded += [val] * occ\n",
    "    return expanded\n",
    "\n",
    "def normalize(data):\n",
    "    total = sum(data.values())\n",
    "    percs = {k: (v/total) for k, v in data.items()}\n",
    "    return percs\n",
    "\n",
    "def accumulate(data):\n",
    "    global curr\n",
    "    curr = 0\n",
    "    def acc(val): # just for the list comprehension\n",
    "        global curr\n",
    "        curr += val\n",
    "        return curr\n",
    "    return {k: acc(v) for k, v in sorted(data.items())}\n",
    "    \n",
    "def to_hdr(data):\n",
    "    # treat negative (>1.0) and exact 1.0 values and very high values for v\n",
    "    MAX_ACCURACY = 1000000000\n",
    "    return {k: 1/(1-v) for k, v in data.items() if not (1-v) == 0.0 and not 1/(1-v) < 0 and not 1/(1-v) > MAX_ACCURACY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hist_data(paths, basepath='/', histogram_file='histogram.csv', round_ms_digits=3, **kwargs):\n",
    "    data = {}\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "        \n",
    "    print('Using {} digits for ms histogram'.format(round_ms_digits))\n",
    "        \n",
    "    for path in paths:\n",
    "        name = None\n",
    "        if not isinstance(path, tuple):\n",
    "            name = path.replace('_', '-') # tex friendly path\n",
    "        else:\n",
    "            name = path[1]\n",
    "            path = path[0]\n",
    "            \n",
    "        extended_path = os.path.join(basepath, path)\n",
    "        experiment = os.path.join(extended_path, histogram_file)\n",
    "        rprint('Processing ' + extended_path)\n",
    "        \n",
    "        subexperiments = glob(experiment)\n",
    "        update_name = False\n",
    "        base_name = name\n",
    "        if len(subexperiments) > 1:\n",
    "            update_name = True\n",
    "        \n",
    "        for exp in subexperiments:\n",
    "            # replace everything that is not wildcard\n",
    "            if not (basepath == '.' or basepath == '..'):\n",
    "                histo = exp.replace(basepath, '')\n",
    "            histo = histo.replace(path, '')\n",
    "            histo = histo.replace(histogram_file, '')\n",
    "            histo = histo.replace('//', '/')\n",
    "            histo = histo[:-1]\n",
    "            \n",
    "            rprint('Subexperiment ' + histo)\n",
    "            if update_name:\n",
    "                name = base_name + histo\n",
    "                \n",
    "            # load data\n",
    "            try:\n",
    "                raw_data = read_2c_csv(exp)\n",
    "            except FileNotFoundError as exce:\n",
    "                rprint('Skipping - {}'.format(exce), file=sys.stderr)\n",
    "                continue\n",
    "                \n",
    "            # different processing steps\n",
    "            ms_data = to_microsecond(raw_data)\n",
    "            hist_data = to_ms_bins(ms_data, round_ms_digits=round_ms_digits)\n",
    "            box_data = to_expanded(ms_data)\n",
    "            normalized_data = normalize(hist_data)\n",
    "            accumulated_data = accumulate(normalized_data)\n",
    "            hdr_data = to_hdr(accumulated_data)\n",
    "            \n",
    "            \n",
    "            # store data\n",
    "            data[name] = {}\n",
    "            data[name]['hist'] = hist_data\n",
    "            data[name]['hist_norm'] = normalized_data\n",
    "            data[name]['cdf'] = accumulated_data\n",
    "            data[name]['hdr'] = hdr_data\n",
    "            data[name]['box'] = box_data\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_sequence_data(paths, basepath='/', sequence_file='sequence.csv', **kwargs):\n",
    "    data = {}\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "\n",
    "    for path in paths:\n",
    "        name = None\n",
    "        if not isinstance(path, tuple):\n",
    "            name = path.replace('_', '-') # tex friendly path\n",
    "        else:\n",
    "            name = path[1]\n",
    "            path = path[0]\n",
    "            \n",
    "        extended_path = os.path.join(basepath, path)\n",
    "        experiment = os.path.join(extended_path, sequence_file)\n",
    "        rprint('Processing ' + extended_path)\n",
    "        \n",
    "        subexperiments = glob(experiment)\n",
    "        update_name = False\n",
    "        base_name = name\n",
    "        if len(subexperiments) > 1:\n",
    "            update_name = True\n",
    "        \n",
    "        for exp in subexperiments:\n",
    "            # remove basepath and filename from what we will use as label\n",
    "            histo = exp.replace(basepath, '')\n",
    "            histo = histo.replace(sequence_file, '')\n",
    "            \n",
    "            rprint('Subexperiment ' + histo)\n",
    "            if update_name:\n",
    "                name = base_name + histo\n",
    "        \n",
    "            # load data\n",
    "            try:\n",
    "                raw_data = read_2c_csv(exp)\n",
    "            except FileNotFoundError as exce:\n",
    "                rprint('Skipping - {}'.format(exce), file=sys.stderr)\n",
    "                continue\n",
    "            \n",
    "            # different processing steps\n",
    "            seq_data = to_microsecond(raw_data, keys=False, values=True)\n",
    "            \n",
    "            \n",
    "            # store data\n",
    "            data[name] = {}\n",
    "            data[name]['seq'] = seq_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_values(xs, ys, sort_by='xs'):\n",
    "    # necessary for python <3.6\n",
    "    if sort_by == 'xs':\n",
    "        sort_by = 0\n",
    "    else:\n",
    "        sort_by = 1\n",
    "    tup = zip(xs, ys)\n",
    "    tup = sorted(tup, key=lambda x: x[sort_by])\n",
    "    xs = [x for x,_ in tup]\n",
    "    ys = [y for _,y in tup]\n",
    "    return xs, ys\n",
    "\n",
    "def plot_sequence(data, name='', **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    max_value = 0\n",
    "    min_value = 1000000\n",
    "    for exp, data in sorted(data.items()):\n",
    "        hist = data['seq']\n",
    "        xs = list(hist.keys())\n",
    "        ys = list(hist.values())\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        max_value=max(max_value, max(xs))\n",
    "        min_value=min(min_value, min(xs))\n",
    "        ax.plot(xs, ys, marker='o', markersize=1, linestyle='', label=exp)\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='Latency [$\\mu$s]',\n",
    "           xlabel='Number [-]')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.xlim(left=min_value)\n",
    "    plt.xlim(right=max_value)\n",
    "    \n",
    "    save_plt('sequence', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data, name='', key='hist', ymax=None, ylabel='Occurence [-]',\n",
    "              historgram_bar_width=0.005, **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    print('Gathering data for histograms. If this takes too long, adjust round_ms_digits')\n",
    "    \n",
    "    max_value = 0\n",
    "    data_points = 0\n",
    "    for exp, data in sorted(data.items()):\n",
    "        hist = data[key]\n",
    "        xs = list(hist.keys())\n",
    "        if key == 'hist':\n",
    "            factor = 1\n",
    "        else:\n",
    "            # assume normalized\n",
    "            factor = 100\n",
    "        ys = [factor * val for val in hist.values()]\n",
    "        if not ys:\n",
    "            continue\n",
    "        tup = zip(xs, ys)\n",
    "        tup = sorted(tup, key=lambda x: x[0])\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        data_points += len(ys)\n",
    "        max_value=max(max_value, max(ys))\n",
    "        ax.bar(xs, ys, width=historgram_bar_width, label=exp)\n",
    "\n",
    "    print('Total amount of histogram of data points: {}'.format(data_points))\n",
    "    \n",
    "    if not ymax:\n",
    "        ymax = max_value\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=ymax)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel=ylabel,\n",
    "           xlabel='Latency [$\\mu$s]')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.xlim(left=0)\n",
    "    \n",
    "    save_plt(key, name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf(data, name='', **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    for exp, data in sorted(data.items()):\n",
    "        cdf = data['cdf']\n",
    "        xs = list(cdf.keys())\n",
    "        ys = [100 * val for val in cdf.values()]\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        ax.plot(xs, ys, label=exp)\n",
    "\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=100)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='CDF [\\%]',\n",
    "           xlabel='Latency [$\\mu$s]')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.xlim(left=0)\n",
    "    \n",
    "    save_plt('cdf', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hdr(data, name='', **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    max_value = 0\n",
    "    min_value = 10000000000\n",
    "    data_points = 0\n",
    "    for exp, data in sorted(data.items()):\n",
    "        hdr = data['hdr']\n",
    "        xs = list(hdr.values())\n",
    "        ys = list(hdr.keys())\n",
    "        if not ys:\n",
    "            continue\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        data_points += len(ys)\n",
    "        max_value=max(max_value, max(ys))\n",
    "        min_value=min(min_value, min(ys))\n",
    "        ax.plot(xs, ys, label=exp)\n",
    "              \n",
    "    print('Total amount of HDR data points: {}'.format(data_points))\n",
    "            \n",
    "    # automatically determine min/max based on min/max values log10\n",
    "    log_max = pow(10, math.ceil(math.log10(max_value)))\n",
    "    log_min = pow(10, math.floor(math.log10(min_value)))\n",
    "    plt.ylim(bottom=log_min)\n",
    "    plt.ylim(top=log_max)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(xlabel='Percentile [\\%] (log)',\n",
    "           ylabel='Latency [$\\mu$s] (log)')\n",
    "    ax.set_xscale('log', subsx=[])\n",
    "    ax.set_yscale('log')\n",
    "    ticks = [1, 2, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "    labels = [\"$0$\", \"$50$\", \"$90$\", \"$99$\", \"$99.9$\", \"$99.99$\", \"$99.999$\", \"$99.9999$\"]\n",
    "    plt.xticks(ticks, labels)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.xlim(left=1)\n",
    "    # TODO determine xlim right\n",
    "\n",
    "    save_plt('hdr', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(data, name='', **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for exp, data in sorted(data.items()):\n",
    "        values = data['box']\n",
    "        boxes.append(values)\n",
    "        labels.append(exp)\n",
    "    ax.boxplot(boxes, showfliers=True, whis=1.5, labels=labels, patch_artist=True,\n",
    "               medianprops=dict(color='TUMOrange'),\n",
    "               boxprops=dict(facecolor='TUMWhite', color='TUMBlack'),\n",
    "               \n",
    "            )\n",
    "            \n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xticks(ticks=range(1, len(labels) + 1), labels=labels)\n",
    "    plt.xlim(left=0.5, right=len(labels) + 0.5)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(xlabel='',\n",
    "           ylabel='Latency [$\\mu$s]')\n",
    "\n",
    "    save_plt('box', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_percentile(data, percentile):\n",
    "    entries = len(data)\n",
    "    if entries < get_accuracy(percentile):\n",
    "        raise IndexError\n",
    "    index = entries * percentile / 100\n",
    "    index = int(index)\n",
    "    return data[index-1]\n",
    "\n",
    "def get_accuracy(f):\n",
    "    # number of entries required by percentile\n",
    "    # 99.99 -> 9999\n",
    "    s = str(f)\n",
    "    parts = s.split('.')\n",
    "    if len(parts) == 1:\n",
    "        return f\n",
    "    total = len(parts[1])\n",
    "    res = f * (10**total)\n",
    "    return res\n",
    "\n",
    "def plot_loop(name, content, mapping, hist_data, key=None,\n",
    "              additional_plot_exports=None, only_direction=None, only_core_id=None,\n",
    "              loop_log_scale=False, **kwargs):\n",
    "    if not additional_plot_exports:\n",
    "        additional_plot_exports = []\n",
    "    if not key:\n",
    "        key = [50]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    axis_label = None\n",
    "    xss = {}\n",
    "    yss = {}\n",
    "    mapped = {}\n",
    "    \n",
    "    # gather data based on mapping\n",
    "    for exp, run, type, label in content:\n",
    "        axis_label = list(type.keys())[0]\n",
    "        if label not in xss:\n",
    "            xss[label] = []\n",
    "            yss[label] = {}\n",
    "        xss[label].append(list(type.values())[0])\n",
    "        try:\n",
    "            mapped[label] = hist_data[mapping[exp][run]]\n",
    "        except KeyError as exce:\n",
    "            continue\n",
    "        else:\n",
    "            data = mapped[label]\n",
    "            for percentile in key:\n",
    "                perc = 0\n",
    "                try:\n",
    "                    perc = get_nth_percentile(data['box'], percentile)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                if not percentile in yss[label]:\n",
    "                    yss[label][percentile] = []\n",
    "                yss[label][percentile].append(perc)\n",
    "        \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    labels = []\n",
    "    max_y_value = -1\n",
    "    max_x_value = 0\n",
    "    min_x_value = 1000000\n",
    "    for exp, data in sorted(mapped.items()):\n",
    "        for percentile in sorted(key):\n",
    "            ys = yss[exp][percentile]\n",
    "            xs = xss[exp]\n",
    "            zipped = list(zip(xs, ys))\n",
    "            zipped.sort(key=lambda tup: tup[0])\n",
    "            xs, ys = zip(*zipped)\n",
    "            x_data.append(xs)\n",
    "            y_data.append(ys)\n",
    "            labels.append(label)\n",
    "            \n",
    "            max_y_value = max(max_y_value, max(ys))\n",
    "            max_x_value = max(max_x_value, max(xs))\n",
    "            min_x_value = min(max_x_value, min(xs))\n",
    "            \n",
    "            ax.plot(xs, ys, marker='x', label = '{} {}%ile'.format(exp, percentile))\n",
    "            \n",
    "    if kwargs.get('model_parameters'):\n",
    "        modelp = kwargs.get('model_parameters')\n",
    "        # add model now that we made all configs in case of abort\n",
    "        error_plot = []\n",
    "        derivatives = []\n",
    "        maximas = []\n",
    "            \n",
    "        num_models = len(key) * modelp.get('num_graphs', 1)\n",
    "        for i in range(0, num_models):\n",
    "            if not len(x_data) >= i + 1:\n",
    "                break\n",
    "            end = 0\n",
    "            if modelp.get('end'):\n",
    "                num = len(x_data[i])\n",
    "                end = num - modelp.get('end')\n",
    "        \n",
    "            # calculate derivative\n",
    "            derivative = calculate_2nd_derivative(x_data[i], y_data[i], log=loop_log_scale)\n",
    "            maxima = get_k_maxima(derivative[2], k=modelp.get('maxima_k', 10),\n",
    "                                  j=modelp.get('maxima_j', 0), max_index=end)\n",
    "            maximas.append(maxima)\n",
    "            derivative.append(maxima)\n",
    "            derivatives.append((x_data[i], derivative, i))\n",
    "            \n",
    "            error_plot += add_model(x_data, y_data, ax, modelp,\n",
    "                                    maximum=max_y_value * 1.2, graph=i, end=end, maxima=maxima)\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=min_x_value)\n",
    "    plt.xlim(right=max_x_value)\n",
    "    if loop_log_scale:\n",
    "        plt.xscale('log')\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='Latency [$\\mu$s]',\n",
    "           xlabel=axis_label)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    long_key = '_'.join([str(p) for p in key])\n",
    "    \n",
    "    save_plt('loop_{}'.format(long_key), name=name)\n",
    "    for ape in additional_plot_exports:\n",
    "        rprint('Additional export as {}'.format(ape))\n",
    "        savefig('figures/{}_loop_{}.{}'.format(name, long_key, ape), format=ape)\n",
    "    plt.show()\n",
    "    \n",
    "    if kwargs.get('model_parameters'):\n",
    "        add_error_plot(plt, error_plot, name, key=key, log_scale=loop_log_scale, axis_label=axis_label,\n",
    "                       additional_plot_exports=additional_plot_exports)\n",
    "        \n",
    "        add_derivative_plot(plt, derivatives, name, key=key, log_scale=loop_log_scale, axis_label=axis_label,\n",
    "                            additional_plot_exports=additional_plot_exports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_sequence(paths, **kwargs):\n",
    "    print('------------- plotting sequence data ------------')\n",
    "    seq_data = extract_sequence_data(paths, **kwargs)\n",
    "    if not seq_data:\n",
    "        rprint('No sequence data found', file=sys.stderr)\n",
    "    else:\n",
    "        plot_sequence(seq_data, **kwargs)\n",
    "        \n",
    "def _plot_default_histogram(hist_data, histogram_plots=True, **kwargs):\n",
    "    print('------------ plotting default histogram data ----------')\n",
    "    # different plot types for histogram data\n",
    "    if histogram_plots:\n",
    "        plot_hist(hist_data, **kwargs)\n",
    "        plot_hist(hist_data, key='hist_norm', ylabel='Occurence [\\%]', **kwargs)\n",
    "    else:\n",
    "        print('skipping histograms')\n",
    "    plot_box(hist_data, **kwargs)\n",
    "    plot_cdf(hist_data, **kwargs)\n",
    "    plot_hdr(hist_data, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(paths, **kwargs):\n",
    "    \n",
    "    if kwargs.get('sequence_file'):\n",
    "        _plot_sequence(paths, **kwargs)\n",
    "    \n",
    "    if kwargs.get('histogram_file'):\n",
    "        # histogram data\n",
    "        hist_data = extract_hist_data(paths, **kwargs)\n",
    "        if not hist_data:\n",
    "            rprint('No histogram data found', file=sys.stderr)\n",
    "            return\n",
    "        \n",
    "        if kwargs.get('default_plots'):\n",
    "            _plot_default_histogram(hist_data, **kwargs)\n",
    "            \n",
    "    if not kwargs.get('percentiles'):\n",
    "        print('you need to define the percentiles of interest as list of lists')\n",
    "        return\n",
    "\n",
    "    if kwargs.get('loop_file'):\n",
    "        _plot_loop(paths, hist_data, plot_loop, metrics=kwargs.get('percentiles'), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will only be triggered if invoked from command-line\n",
    "if not sys.argv[0].endswith('ipykernel_launcher.py'):\n",
    "    run_from_cli()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your edits in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "configuration = None\n",
    "# templated from generator script\n",
    "#$configuration\n",
    "if not configuration:\n",
    "    # default for testing\n",
    "    configuration = {'convert_to_cycles': 2.0,\n",
    " 'dut': 'cesis',\n",
    " 'experiment_name': 'meta_field_writes',\n",
    " 'latency_rates': [0.1, 0.5, 0.7],\n",
    " 'loadgen': 'nida',\n",
    " 'log_scale': '',\n",
    " 'loop_plot_per': ['packet_size'],\n",
    " 'loop_x_axis': 'meta_field_writes',\n",
    " 'model_end': 0,\n",
    " 'model_parts': [1, 2],\n",
    " 'model_start': 0,\n",
    " 'only_core_id': 1,\n",
    " 'perf_stat_events': [['r08d1', 'L1_cache_misses'],\n",
    "                      ['r10d1', 'L2_cache_misses'],\n",
    "                      ['r20d1', 'L3_cache_misses']],\n",
    " 'repetitions': 3,\n",
    " 'result_dir_file': '/home/scholzd/component_benchmarking/experiments/p4_tapas/other/meta_field_writes/result_directory.txt',\n",
    " 'target': 'p4_t4p4s'}\n",
    "    \n",
    "    \n",
    "result_dir = None\n",
    "with open(configuration['result_dir_file'], 'r') as fh:\n",
    "    # one per row, filter duplicates and empty last line\n",
    "    result_dirs = sorted(list(set(fh.read().split('\\n')[:-1])))\n",
    "    \n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print('Results on node ' + hostname)\n",
    "    \n",
    "print('Found result directories')\n",
    "pprint(result_dirs)\n",
    "\n",
    "print('Using configuration:')\n",
    "pprint(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = result_dirs[-1]\n",
    "print('Result data in:')\n",
    "print(result_dir)\n",
    "\n",
    "RESULTS=os.path.join(result_dir, configuration['loadgen'])\n",
    "LOOP_FILENAME = '*_measurement_run*.loop'\n",
    "\n",
    "model_parameters = {\n",
    "    'parts': configuration['model_parts'],\n",
    "    'bruteforce': [2], \n",
    "    'end': configuration['model_end'],\n",
    "    'start': configuration['model_start'],\n",
    "    \n",
    "    'num_graphs': 1,\n",
    "    'show_best_x': 1,\n",
    "    \n",
    "    'maxima_k': 10,\n",
    "    'maxima_j': 0,\n",
    "    \n",
    "    'gamma': 1e-05,\n",
    "    'comp_method': 'sMAPE',\n",
    "    'epsilon': 0.005,\n",
    "    'epsilon_rel': 0.005,\n",
    "}\n",
    "\n",
    "for latency_rate in configuration['latency_rates']:\n",
    "    HISTOGRAM_FILENAME = 'histogram-{}_run*.csv'.format(latency_rate)\n",
    "    plot([\n",
    "          ('', configuration['experiment_name']),\n",
    "         ],\n",
    "         basepath=RESULTS,\n",
    "         name='{}_{}'.format(configuration['target'], latency_rate),\n",
    "         histogram_file=HISTOGRAM_FILENAME,\n",
    "        \n",
    "         percentiles=[[0, 50], [25, 75], [100]],\n",
    "         default_plots=False,\n",
    "         histogram_plots=False,\n",
    "         round_ms_digits=1,\n",
    "        \n",
    "         convert_to_cycles=configuration['convert_to_cycles'],\n",
    "        \n",
    "         loop_file=LOOP_FILENAME,\n",
    "         loop_x_axis=configuration['loop_x_axis'],\n",
    "         loop_plot_per=configuration['loop_plot_per'],\n",
    "         loop_log_scale=configuration['log_scale'],\n",
    "        \n",
    "         model_parameters=model_parameters,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
